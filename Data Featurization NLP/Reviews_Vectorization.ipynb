{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc368c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077655d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  bought several vitality canned dog food produc...      1\n",
       "1  product arrived labeled jumbo salted peanuts p...      0\n",
       "2  confection around centuries light pillowy citr...      1\n",
       "3  looking secret ingredient robitussin believe f...      0\n",
       "4  great taffy great price wide assortment yummy ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_data = pd.read_csv(\"result_df.csv\")\n",
    "reviews_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac243eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text     724\n",
      "Score      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the dataframe\n",
    "nan_counts = reviews_data.isnull().sum()\n",
    "# Display the count of NaN values for each column\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b35bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  bought several vitality canned dog food produc...      1\n",
       "1  product arrived labeled jumbo salted peanuts p...      0\n",
       "2  confection around centuries light pillowy citr...      1\n",
       "3  looking secret ingredient robitussin believe f...      0\n",
       "4  great taffy great price wide assortment yummy ...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove rows with NaN values\n",
    "reviews_data = reviews_data.dropna()\n",
    "\n",
    "# Display the cleaned dataframe\n",
    "reviews_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3dd8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text     0\n",
      "Score    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the dataframe\n",
    "nan_counts = reviews_data.isnull().sum()\n",
    "# Display the count of NaN values for each column\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fa9263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  bought several vitality canned dog food produc...      1\n",
       "1  product arrived labeled jumbo salted peanuts p...      0\n",
       "2  confection around centuries light pillowy citr...      1\n",
       "3  looking secret ingredient robitussin believe f...      0\n",
       "4  great taffy great price wide assortment yummy ...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d45809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242690,) (242690,)\n"
     ]
    }
   ],
   "source": [
    "# Creating the training data :\n",
    "X = reviews_data['Text']\n",
    "y = reviews_data['Score']\n",
    "print(X.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17faf184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (118918,) (118918,)\n",
      "Cross-validation set shape: (50965,) (50965,)\n",
      "Test set shape: (72807,) (72807,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "# Split the data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "\n",
    "# Further split the training set into training and cross-validation sets (70% train, 30% cross-validation of the original training set)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.3, random_state=40)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Cross-validation set shape:\", X_cv.shape, y_cv.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb6345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the y datasets to local files\n",
    "with open('y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('y_cv.pkl', 'wb') as f:\n",
    "    pickle.dump(y_cv, f)\n",
    "with open('y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df5a49",
   "metadata": {},
   "source": [
    "## 1. BoW Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f982915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BoW vectorizer to training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 118918/118918 [00:02<00:00, 45316.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BoW vectorizer to CV data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 50965/50965 [00:01<00:00, 45981.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BoW vectorizer to test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 72807/72807 [00:01<00:00, 44559.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW vectorization complete and saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CountVectorizer for BoW\n",
    "count_vect = CountVectorizer(ngram_range=(1, 1), min_df=5)\n",
    "\n",
    "# Apply vectorizer with progress bar\n",
    "print(\"Applying BoW vectorizer to training data...\")\n",
    "X_train_bow = count_vect.fit_transform(tqdm(X_train))\n",
    "print(\"Applying BoW vectorizer to CV data...\")\n",
    "X_cv_bow = count_vect.transform(tqdm(X_cv))\n",
    "print(\"Applying BoW vectorizer to test data...\")\n",
    "X_test_bow = count_vect.transform(tqdm(X_test))\n",
    "\n",
    "# Save the BoW vectorized matrices\n",
    "with open('X_train_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_bow, f)\n",
    "with open('X_cv_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(X_cv_bow, f)\n",
    "with open('X_test_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_bow, f)\n",
    "\n",
    "print(\"BoW vectorization complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f1271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3e340c6",
   "metadata": {},
   "source": [
    "## 2. TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2380cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying TF-IDF vectorizer to training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 118918/118918 [00:02<00:00, 44973.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying TF-IDF vectorizer to CV data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 50965/50965 [00:01<00:00, 44483.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying TF-IDF vectorizer to test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 72807/72807 [00:01<00:00, 44450.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorization complete and saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1, 1), min_df=5)\n",
    "\n",
    "# Apply vectorizer with progress bar\n",
    "print(\"Applying TF-IDF vectorizer to training data...\")\n",
    "X_train_tfidf = tfidf_vect.fit_transform(tqdm(X_train))\n",
    "print(\"Applying TF-IDF vectorizer to CV data...\")\n",
    "X_cv_tfidf = tfidf_vect.transform(tqdm(X_cv))\n",
    "print(\"Applying TF-IDF vectorizer to test data...\")\n",
    "X_test_tfidf = tfidf_vect.transform(tqdm(X_test))\n",
    "\n",
    "# Save the TF-IDF vectorized matrices\n",
    "with open('X_train_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_tfidf, f)\n",
    "with open('X_cv_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_cv_tfidf, f)\n",
    "with open('X_test_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_tfidf, f)\n",
    "\n",
    "print(\"TF-IDF vectorization complete and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee6124",
   "metadata": {},
   "source": [
    "## 3. Word2Vec Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e512536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 118918/118918 [00:00<00:00, 172815.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Word2Vec vectorizer to training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 118918/118918 [00:10<00:00, 11564.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Word2Vec vectorizer to CV data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 50965/50965 [00:04<00:00, 11502.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Word2Vec vectorizer to test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 72807/72807 [00:06<00:00, 12083.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vectorization complete and saved.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the reviews for Word2Vec\n",
    "X_train_tokens = [review.split() for review in X_train]\n",
    "X_cv_tokens = [review.split() for review in X_cv]\n",
    "X_test_tokens = [review.split() for review in X_test]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "print(\"Training Word2Vec model...\")\n",
    "w2v_model = Word2Vec(sentences=tqdm(X_train_tokens), vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# Vectorize the training, CV, and test data using the Word2Vec model\n",
    "def vectorize_w2v(tokens, model):\n",
    "    vectorized = []\n",
    "    for token_list in tqdm(tokens):\n",
    "        vector = np.mean([model.wv[word] for word in token_list if word in model.wv], axis=0)\n",
    "        if isinstance(vector, np.ndarray):\n",
    "            vectorized.append(vector)\n",
    "        else:\n",
    "            vectorized.append(np.zeros(model.vector_size))\n",
    "    return np.array(vectorized)\n",
    "\n",
    "print(\"Applying Word2Vec vectorizer to training data...\")\n",
    "X_train_w2v = vectorize_w2v(X_train_tokens, w2v_model)\n",
    "print(\"Applying Word2Vec vectorizer to CV data...\")\n",
    "X_cv_w2v = vectorize_w2v(X_cv_tokens, w2v_model)\n",
    "print(\"Applying Word2Vec vectorizer to test data...\")\n",
    "X_test_w2v = vectorize_w2v(X_test_tokens, w2v_model)\n",
    "\n",
    "# Save the Word2Vec vectorized matrices\n",
    "with open('X_train_w2v.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_w2v, f)\n",
    "with open('X_cv_w2v.pkl', 'wb') as f:\n",
    "    pickle.dump(X_cv_w2v, f)\n",
    "with open('X_test_w2v.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_w2v, f)\n",
    "\n",
    "print(\"Word2Vec vectorization complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f00a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb398887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8195a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3770f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc9f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
